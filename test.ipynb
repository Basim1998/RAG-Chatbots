{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectore Storage using Hugging Face Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\genai\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\BASIM ASLAM\\AppData\\Local\\llama_index\\models--BAAI--bge-small-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 15/15 [00:01<00:00, 11.39it/s]\n",
      "Generating embeddings: 100%|██████████| 19/19 [00:03<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisting index to ./storage...\n",
      "\n",
      "==================================================\n",
      "QUERY: What is invehicle infotainment?\n",
      "==================================================\n",
      "\n",
      "RESPONSE WITH SOURCES:\n",
      "Final Response: In-vehicle infotainment (IVI) is a technology that\n",
      "integrates entertainment, multimedia, and driver-assisting\n",
      "technologies into a single module. It provides a range of features,\n",
      "including rear seat entertainment, external connectivity, connectivity\n",
      "to mobile devices, advanced driver assistance systems, and security\n",
      "systems. IVI systems are designed to provide excellent entertainment\n",
      "facilities, assist drivers while parking, alert them to congested\n",
      "traffic routes, and suggest alternative paths. They also provide\n",
      "internet connectivity inside the car.\n",
      "______________________________________________________________________\n",
      "Source Node 1/4\n",
      "Node ID: 88cb1410-693e-4702-ac47-60401adaeb4b\n",
      "Similarity: 0.7787228429712563\n",
      "Text: International Journal of Advanced Computational Engineering and\n",
      "Networking , ISSN: 2320-2106  Volume- 1, Issue- 7, Sept-2013   In-\n",
      "Vehicle Infotainment Systems     27  IN-VEHICLE INFOTAINMENT SYSTEMS\n",
      "1AADARSH KENIA, 2SNEHA KADAM, 3POOJA PURUSHOTHAMAN    Department of\n",
      "Computer Science, F.C.R.I.T, Vashi.  Email: aadarshkenia@gmail.com,\n",
      "snehakada...\n",
      "______________________________________________________________________\n",
      "Source Node 2/4\n",
      "Node ID: 5c9a3268-d7a8-4e4f-ba9f-1d9a4702bf7b\n",
      "Similarity: 0.7433543769635581\n",
      "Text: Infotainment and Telematics      Copyright © Strategy Analytics\n",
      "2018  |  www.strategyanalytics.com 9 of 9  3. Preparing for the\n",
      "Cockpit of the Future  Automakers face a more complex engineering\n",
      "environment than they ever have before. More advanced safety and\n",
      "infotainment technologies have been introduced in new vehicles in\n",
      "production today, and...\n",
      "______________________________________________________________________\n",
      "Source Node 3/4\n",
      "Node ID: 94dda001-6f5e-42b5-b7cd-9e35080203c9\n",
      "Similarity: 0.7431600435477657\n",
      "Text: International Journal of Advanced Computational Engineering and\n",
      "Networking , ISSN: 2320-2106  Volume- 1, Issue- 7, Sept-2013   In-\n",
      "Vehicle Infotainment Systems     28  Interface is the unit that a user\n",
      "interacts with, in order  to play music in his car. This interface is\n",
      "a  physical  unit that contains a CD/DVD dr ive, a USB port, etc.\n",
      "Thus a us...\n",
      "______________________________________________________________________\n",
      "Source Node 4/4\n",
      "Node ID: 531c33f7-a915-4f82-b141-c510d37c3f9d\n",
      "Similarity: 0.7192405718331794\n",
      "Text: Infotainment and Telematics      www.strategyanalytics.com\n",
      "December, 2018  Greg Basich             Automakers across the globe\n",
      "are designing vehicle cockpits  with an ever-growing number of\n",
      "advanced features, many of  which are influenced by the wide array of\n",
      "new technologies  that consumers are using on a daily basis. In\n",
      "addition, the  auto ...\n",
      "\n",
      "RESPONSE TEXT ONLY:\n",
      "In-vehicle infotainment (IVI) is a technology that integrates entertainment, multimedia, and driver-assisting technologies into a single module. It provides a range of features, including rear seat entertainment, external connectivity, connectivity to mobile devices, advanced driver assistance systems, and security systems. IVI systems are designed to provide excellent entertainment facilities, assist drivers while parking, alert them to congested traffic routes, and suggest alternative paths. They also provide internet connectivity inside the car.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "QUERY: What are subwoofers?\n",
      "==================================================\n",
      "\n",
      "RESPONSE WITH SOURCES:\n",
      "Final Response: Subwoofers are specialized loudspeakers that are\n",
      "capable of reproducing only low ranged audio frequencies known as\n",
      "bass.\n",
      "______________________________________________________________________\n",
      "Source Node 1/1\n",
      "Node ID: 4aebefc6-2af7-42e2-9627-dc8045ba3d8c\n",
      "Similarity: 0.7273862872903336\n",
      "Text: These modules are:  · Rear seat entertainment.  · Internet\n",
      "connectivity in cars.  · External connectivity.  · Advanced driver\n",
      "assistance functions.  · Security issues in cars and systems for the\n",
      "same.    II. MODULES    A. REAR SEAT ENTERTAINMENT    Rear seat\n",
      "entertainment can be divided into  two sub  modules viz. the audio\n",
      "system and the video ...\n",
      "\n",
      "RESPONSE TEXT ONLY:\n",
      "Subwoofers are specialized loudspeakers that are capable of reproducing only low ranged audio frequencies known as bass.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "QUERY: What are amplifiers?\n",
      "==================================================\n",
      "\n",
      "RESPONSE WITH SOURCES:\n",
      "Final Response: Amplifiers 'amplify' an audio output. In other words,\n",
      "they just increase the intensity of sound without affecting sound\n",
      "quality.\n",
      "______________________________________________________________________\n",
      "Source Node 1/1\n",
      "Node ID: 4aebefc6-2af7-42e2-9627-dc8045ba3d8c\n",
      "Similarity: 0.6274496782286856\n",
      "Text: These modules are:  · Rear seat entertainment.  · Internet\n",
      "connectivity in cars.  · External connectivity.  · Advanced driver\n",
      "assistance functions.  · Security issues in cars and systems for the\n",
      "same.    II. MODULES    A. REAR SEAT ENTERTAINMENT    Rear seat\n",
      "entertainment can be divided into  two sub  modules viz. the audio\n",
      "system and the video ...\n",
      "\n",
      "RESPONSE TEXT ONLY:\n",
      "Amplifiers 'amplify' an audio output. In other words, they just increase the intensity of sound without affecting sound quality.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.langchain import LangChainLLM\n",
    "from langchain_groq import ChatGroq\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "\n",
    "# Ensure your GROQ_API_KEY is set\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"your-groq-api-key\"\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Create LangChain Groq LLM\n",
    "langchain_llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0.0,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Wrap it for LlamaIndex\n",
    "llm = LangChainLLM(llm=langchain_llm)\n",
    "\n",
    "# Set the global LLM in Settings\n",
    "Settings.llm = llm\n",
    "\n",
    "# Use a local embedding model\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# Define persistence directory\n",
    "PERSIST_DIR = \"./storage\"\n",
    "\n",
    "# Check if storage already exists\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # Load the documents and create the index\n",
    "    print(\"Creating new index...\")\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        show_progress=True\n",
    "    )\n",
    "    # Store it for later\n",
    "    print(f\"Persisting index to {PERSIST_DIR}...\")\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # Load the existing index\n",
    "    print(f\"Loading existing index from {PERSIST_DIR}...\")\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Create retriever with similarity search\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=4\n",
    ")\n",
    "\n",
    "# Create postprocessor to filter low-relevance results\n",
    "postprocessor = SimilarityPostprocessor(similarity_cutoff=0.60)\n",
    "\n",
    "# Create query engine with retriever and postprocessor\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[postprocessor]\n",
    ")\n",
    "\n",
    "# Example queries\n",
    "queries = [\n",
    "    \"What is invehicle infotainment?\",\n",
    "    \"What are subwoofers?\",\n",
    "    \"What are amplifiers?\"\n",
    "]\n",
    "\n",
    "# Run queries\n",
    "for query in queries:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    response = query_engine.query(query)\n",
    "    \n",
    "    # Print full response with sources\n",
    "    print(\"\\nRESPONSE WITH SOURCES:\")\n",
    "    pprint_response(response, show_source=True)\n",
    "    \n",
    "    # Print just the response text\n",
    "    print(\"\\nRESPONSE TEXT ONLY:\")\n",
    "    print(response)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectore storage using sentence window embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\genai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "python-dotenv could not parse statement starting at line 1\n",
      "python-dotenv could not parse statement starting at line 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid index found in './storage_sentence_window'. Ready to use.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.langchain import LangChainLLM\n",
    "from langchain_groq import ChatGroq\n",
    "from llama_index.core import Settings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"./data\"  # Directory containing your documents\n",
    "PERSIST_DIR = \"./storage_sentence_window\"  # Storage for sentence window index\n",
    "WINDOW_SIZE = 3  # Same as your default sentence_window_size\n",
    "MODEL_NAME = \"llama3-70b-8192\"  # Same as your default llm_model\n",
    "TEMPERATURE = 0.1  # Same as your default temperature\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "langchain_llm = ChatGroq(model=MODEL_NAME, temperature=TEMPERATURE, max_retries=2)\n",
    "llm = LangChainLLM(llm=langchain_llm)\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# Check if data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    raise FileNotFoundError(f\"Data directory '{DATA_DIR}' not found. Please create it and add documents.\")\n",
    "\n",
    "# Check if storage directory is valid\n",
    "def is_valid_storage_dir(directory):\n",
    "    required_files = [\"docstore.json\", \"index_store.json\"]\n",
    "    if not os.path.exists(directory):\n",
    "        return False\n",
    "    return all(os.path.exists(os.path.join(directory, f)) for f in required_files)\n",
    "\n",
    "# Create or rebuild sentence window index\n",
    "try:\n",
    "    if os.path.exists(PERSIST_DIR) and not is_valid_storage_dir(PERSIST_DIR):\n",
    "        print(f\"Invalid or corrupted storage directory '{PERSIST_DIR}'. Deleting and rebuilding...\")\n",
    "        shutil.rmtree(PERSIST_DIR)\n",
    "    \n",
    "    if not os.path.exists(PERSIST_DIR):\n",
    "        print(f\"Creating sentence window index in '{PERSIST_DIR}'...\")\n",
    "        # Load documents\n",
    "        documents = SimpleDirectoryReader(DATA_DIR).load_data()\n",
    "        if not documents:\n",
    "            raise ValueError(f\"No documents found in '{DATA_DIR}'.\")\n",
    "        \n",
    "        # Create node parser\n",
    "        node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "            window_size=WINDOW_SIZE,\n",
    "            window_metadata_key=\"window\",\n",
    "            original_text_metadata_key=\"original_text\"\n",
    "        )\n",
    "        \n",
    "        # Parse nodes\n",
    "        nodes = node_parser.get_nodes_from_documents(documents)\n",
    "        \n",
    "        # Create and persist index\n",
    "        storage_context = StorageContext.from_defaults()\n",
    "        index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "        index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "        print(f\"Index successfully created and saved to '{PERSIST_DIR}'.\")\n",
    "    else:\n",
    "        print(f\"Valid index found in '{PERSIST_DIR}'. Ready to use.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating index: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
